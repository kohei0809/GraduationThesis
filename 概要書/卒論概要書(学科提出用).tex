\documentclass[10pt,a4j,twocolumn]{jsarticle}
\usepackage{csbstp}
\usepackage{times}
%\usepackage[dvips]{graphics}
%\usepackage[dvips]{graphicx}
\usepackage[dvipdfmx]{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{here}

\title{マルチエージェント協調巡回問題における
交渉による\\エージェントの計画停止の
自律的な学習手法の提案}%５はタイトルと氏名の間隔。調整すること
\etitle{英語のタイトル}%今回は無くてもよい。
\author{立木　創太}
\studentid{1W162255-0}
\university{早稲田大学}%省略可
\faculty{基幹理工学部}%省略可
\department{情報通信学科}%省略可
\type{卒業論文}%省略可
\nendo{2019}
\hizuke{2020年2月4日}
\advisor{菅原~俊治}%省略可

\begin{document}
\nocite{*}

\maketitle

%\large
%\baselineskip=15pt

\section{序論}
近年, 人工知能に対する関心が高まり, インテリジェントなプログラムやロボットの利用も身近になってきた. これらの利用の中には, 広い空間や多くの作業を求められるものもあり, 複数のエージェントによる協調や調整が求められることもある. このような問題に広い環境を協力して巡回するマルチエージェント協調巡回問題があり, セキュリティ巡回, 清掃等の利用が考えられる. しかし, エージェントの協調には, 情報取得の困難さや, 適切な行動が環境の他のエージェントの行動に影響されるということがある. このため, 効率的な行動を発現するための自律的戦略学習手法が必要である.  
\par
マルチエージェント協調巡回問題における, 協調手法は大きく分けて, あらかじめ領域を分割する手法と, 明示的な領域分割を行わず, 周囲の行動に合わせて適切な戦略をとる手法\cite{yoneda2013autonomous}\cite{2015杉山LD}\cite{KAIS2019}がある. 本研究では, 環境の構造に影響されづらい, 後者の手法を選択する. 例えば, \cite{yoneda2013autonomous}では, 各地点の訪問要求頻度が与えられたとき, 各エージェントが自律的に適切な行動戦略をとる手法を提案している. \cite{2015杉山LD}では, \cite{yoneda2013autonomous}の手法を改良して, 起きるイベントを観測できるときにその発生頻度を学習しながら協調行動を決定する手法を提案している. \cite{KAIS2019}では, さらに, エージェント間の交渉を追加して, 環境の急激な変化に対する頑健性を高め, 効率も向上させた.
\par
しかし, これらの手法では, エージェントが停止したときに, 長期的には対応できるものの一時的な効率低下を招いた. これはセキュリティや安全巡回では問題となるが, ロボット等は機械であり, インスペクション等のやや長期の停止は免れない. 他方これらの場合, 停止するエージェントがあらかじめ判明しているという特徴もある. そこで, 本研究では, \cite{KAIS2019}の手法をベースに, 計画停止前後での急激なパフォーマンスの悪化を防ぐことを目的とする. なお, 本研究では, マルチエージェント協調巡回問題の中でも, 比較的身近なマルチエージェント巡回清掃を例にして説明する.

\section{モデルの定義}
\subsection{環境の定義}
エージェントが清掃を行う環境を2次元ベクトル空間に埋め込み可能なグラフ$G=(V, E)$で表す. ここで, $V=\{v_1, \cdots ,v_n\}$はノード集合であり, 各エージェントやごみ, 障害物は$v \in V$上に存在する. $E$は, エッジの集合で, ノード$v_i$と$v_j$間のエッジを$e_{i,j} \in E$と表す. 本環境では, エッジの長さをすべて1とする. ノード$v_i$から$v_j$への経路が存在するとき, この2つのノード間の最短距離を$d(v_i, v_j)$, ユークリッド距離を$m(v_i, v_j)$と表す. 離散時間を導入し, その最小単位を1ステップとする. 各エージェントは, 1ステップで隣接ノードに移動し, そのノードのごみの回収を行う.
\par
各ノード$v$の時刻$t$におけるごみの量$L_t(v)$は, そのノードの実際のごみの発生確率$p(v)$に基づいて, 毎ステップごとに以下の式で確率的に更新される.
\[
L_t(v)= \left \{
\begin{array}{ll}
L_{t-1}(v)+1\ &\textrm{(ごみの発生時)} \\
L_{t-1}(v)\ &\textrm{(その他)}
\end{array}
\right.
\]
ただし, エージェントが時刻$t$でノード$v$を訪れると, そのノードのごみがすべて回収され, $L_t(v)=0$となる.

\subsection{エージェントの定義}
各エージェントは有限容量のバッテリを持ち, バッテリ容量が0になる前に自身の充電基地に戻る. また, 各エージェントは自身のごみ回収量から推定した各ノード$v$ごみ発生確率$p^i(v)$を持ち, これを重要度と呼ぶ. 各エージェントはそれぞれの重要度の値を目標決定戦略に用いる. エージェントは通信可能範囲内の他のエージェントと, 交渉のための通信ができる. ただし, 過度な通信を防ぐため, 最低通信間隔$T^{i, j}_{limit}$を設定した.
\par
エージェントは目標決定戦略により目標ノード$v_{tar}^i$を決定する. 次に, 経路生成戦略により$v_{tar}^i$までの経路生成したのち, 経路に沿って行動を始める. これをバッテリ残量を参照しながら繰り返す.

\subsection{評価指標}
本研究では評価指標をごみの累積時間の総和$D_{t_s,t_e}$とし, 以下の式で定義する.
\[
D_{t_s,t_e} = \sum_{v \in V} \sum_{t=t_s+1}^{t_e} L_t(v).
\]
ここで, $t_s<t_e$である. $D_{t_s,t_e}$の値が小さいほど, 効率の良い巡回といえる. したがって, ごみを長く放置すると効率が悪くなる.

\begin{figure}
\centering
\includegraphics[width=0.5\hsize]{figures/Graph.eps}
\caption{実験環境}
\label{fig:実験環境}
\end{figure}

\section{提案手法}
提案手法では, 本研究の目的のために\cite{KAIS2019}の手法をベースに, 新たに委託の交渉を加えた. ここでは, 計画停止までの残り時間$T^i_{rem}$と, $T^i_{rem}$を$T^{i,j}_{limit}$で割った計画停止までの予想平均交渉回数$N^i_{rn}$を用いる. 委託の交渉では, 計画停止をするエージェント$i$から計画停止をしないエージェント$j$に, $i$の責任ノード集合$V^i_{self}$から, $p^i(v)$の値が大きい順に$e_g(>0)$個のノードの重要度の一部$p^i(v) \times \delta_c$を渡す. ここで渡されるノード数$e_g$の値を以下の式で決定する.
\[
e_g = \min\left(N^i_{self}, N^i_{dmax}, \left\lfloor \frac{N^i_{self}}{N^i_{rn}} \times \gamma_c \right\rfloor \right).
\]
ここで, $N^i_{dmax}(0 < N^i_{dmax} < N^i_{self})$は, 急激な変化を防ぐための閾値であり, $\gamma_c$は受け渡すノードの数を調整するパラメータである. 重要度を受け渡した後, $e_g$の値にしたがって, $V^{i}_{self}$, $V^{j}_{self}$を変更し, それらの担当ノードを変更する.

\section{評価実験}
\subsection{実験環境}
実験環境は図\ref{fig:実験環境}のように$101 \times 101$の2次元グリッド構造で, 黒色の部分は障害物である. 各ノード$v \in V$の位置を座標$(x_v, y_v)(-50 \leq x_v, y_v \leq 50)$で表す. 環境内のノード集合$V$に対して, ノード$v \in V$の$p(v)$は図\ref{fig:実験環境}の色に応じて, 以下の式で表される.
\[
p(v)= \left \{
\begin{array}{l}
10^{-3}\ (赤色の領域) \\
10^{-4}\ (オレンジ色の領域) \\
10^{-6}\ (その他)
\end{array}
\right.
\]
エージェント数は20とし, そのうち10台を計画停止させる.

\subsection{実験結果}
従来手法と提案手法の清掃効率の推移を比較したグラフを図\ref{fig:AMTDS/EDCとAMTDS/LSCの清掃効率の推移の比較}に示す. また, 計画停止前後の500000ステップから1500000ステップの間, 既存手法と提案手法の比較を図\ref{fig:500000ステップから1500000ステップまでのAMTDS/EDCとAMTDS/LSCの清掃効率の推移の比較}に示す.
\par
図\ref{fig:AMTDS/EDCとAMTDS/LSCの清掃効率の推移の比較}から提案手法は従来手法と比べて効率の変化を緩和できている. 特に, 図\ref{fig:500000ステップから1500000ステップまでのAMTDS/EDCとAMTDS/LSCの清掃効率の推移の比較}から, 計画停止後, $D(s)$の最大値が従来手法と比べて大きく抑えられていることがわかる. このことから, 提案手法は本研究の目的を達成できたといえる. しかし, 効率の急激な悪化が完全になくなったとは言えないため, 効率の急激悪化を更に緩和した手法を考案する必要がある.
\begin{figure}
\centering
\includegraphics[width=0.85\hsize]{figures/ds_graph_3600_ave_compare_10_01-20 11-30-04 robots-number=20.eps}
\caption{AMTDS/EDCとAMTDS/LSCの清掃効率の推移の比較}
\label{fig:AMTDS/EDCとAMTDS/LSCの清掃効率の推移の比較}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.8\hsize]{figures/ds_graph_3600_ave_compare_PlannedStop_10_01-20 11-30-04 robots-number=20.eps}
\caption{500000ステップから1500000ステップまでのAMTDS/EDCとAMTDS/LSCの清掃効率の推移の比較}
\label{fig:500000ステップから1500000ステップまでのAMTDS/EDCとAMTDS/LSCの清掃効率の推移の比較}
\end{figure}

\section{結論}
本研究では, マルチエージェント巡回清掃において, 計画停止による効率の急激な悪化を緩和する手法を提案した. 今後の課題は, 計画停止による効率悪化の更なる減少を目指すことである. 

\bibliographystyle{junsrt}
\bibliography{ref}

\end{document}